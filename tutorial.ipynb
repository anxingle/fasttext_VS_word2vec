{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: /home/tf/workspace/anxingle/research/fastText/nltk_data: Is a directory\r\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "#nltk.download() \n",
    "#布朗语料库，如果使用预训练模型，则不需要\n",
    "# Generate brown corpus text file\n",
    "with open('brown_corp.txt', 'w+') as f:\n",
    "    for word in nltk.corpus.brown.words():\n",
    "        f.write('{word} '.format(word=word))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 下载text8 语料库 (a 100 MB sample of cleaned wikipedia text)\n",
    "!wget http://mattmahoney.net/dc/text8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 下载问答语料库, 测试用！ questions-words.txt to be used for comparing word embeddings\n",
    "!wget https://raw.githubusercontent.com/nicholas-leonard/word2vec/master/questions-words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练fastText模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  15173\n",
      "Number of labels: 0\n",
      "Progress: 100.0%  words/sec/thread: 64536  lr: 0.000000  loss: 2.364343  eta: 0h0m  2.388624  eta: 0h0m 0h0m 0.014048  loss: 2.355604  eta: 0h0m 0.012411  loss: 2.355630  eta: 0h0m   eta: 0h0m \n",
      "Read 17M words\n",
      "Number of words:  71290\n",
      "Number of labels: 0\n",
      "Progress: 100.0%  words/sec/thread: 58843  lr: 0.000000  loss: 1.762129  eta: 0h0m  loss: 2.027483  eta: 0h3m 36200  lr: 0.049568  loss: 2.005225  eta: 0h3m h3m 1.840394  eta: 0h2m 1.835855  eta: 0h1m 0.042200  loss: 1.839727  eta: 0h1m   lr: 0.042057  loss: 1.839946  eta: 0h1m m   eta: 0h1m 0.039760  loss: 1.837245  eta: 0h1m 1.836794  eta: 0h1m 57230  lr: 0.039395  loss: 1.836822  eta: 0h1m 0h1m 0.036827  loss: 1.833853  eta: 0h1m   loss: 1.834084  eta: 0h1m 1.834594  eta: 0h1m   words/sec/thread: 57724  lr: 0.034135  loss: 1.833861  eta: 0h1m 1.833246  eta: 0h1m   lr: 0.032758  loss: 1.825619  eta: 0h1m   lr: 0.032686  loss: 1.825747  eta: 0h1m   eta: 0h1m 0.032370  loss: 1.825444  eta: 0h1m 0h1m 1.817640  eta: 0h1m 0.026425  loss: 1.818563  eta: 0h1m   eta: 0h1m   eta: 0h0m 1.819728  eta: 0h0m 0.022436  loss: 1.816376  eta: 0h0m 1.814990  eta: 0h0m 0h0m 58571  lr: 0.019293  loss: 1.808510  eta: 0h0m 58519  lr: 0.017939  loss: 1.808718  eta: 0h0m   eta: 0h0m h0m   words/sec/thread: 58580  lr: 0.013465  loss: 1.806138  eta: 0h0m 0m 1.808095  eta: 0h0m 0m h0m 0h0m 58708  lr: 0.007374  loss: 1.786748  eta: 0h0m 1.784444  eta: 0h0m 58669  lr: 0.005728  loss: 1.777074  eta: 0h0m 0m 0h0m   lr: 0.000228  loss: 1.761900  eta: 0h0m   words/sec/thread: 58830  lr: 0.000094  loss: 1.762055  eta: 0h0m \n"
     ]
    }
   ],
   "source": [
    "!../fasttext skipgram -input ./brown_corp.txt -output brown_ft_by_anxingle\n",
    "!../fasttext skipgram -input ./text8 -output text8_ft_by_anxingle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练gensim（word2vec）模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom nltk.corpus import brown\\nfrom gensim.models import Word2Vec\\nfrom gensim.models.word2vec import Text8Corpus\\nimport logging\\n\\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\\nlogging.root.setLevel(level=logging.INFO)\\n\\nMODELS_DIR = 'models/'\\n\\nbrown_gs = Word2Vec(brown.sents())\\nbrown_gs.wv.save_word2vec_format(MODELS_DIR + 'brown_gs.vec')\\n\\ntext8_gs = Word2Vec(Text8Corpus('text8'))\\ntext8_gs.wv.save_word2vec_format(MODELS_DIR + 'text8_gs.vec')\\n#model.wv.save_word2vec_format model.wv.save_word2vec_format \\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
    "logging.root.setLevel(level=logging.INFO)\n",
    "\n",
    "MODELS_DIR = 'models/'\n",
    "\n",
    "brown_gs = Word2Vec(brown.sents())\n",
    "brown_gs.wv.save_word2vec_format(MODELS_DIR + 'brown_gs.vec')\n",
    "\n",
    "text8_gs = Word2Vec(Text8Corpus('text8'))\n",
    "text8_gs.wv.save_word2vec_format(MODELS_DIR + 'text8_gs.vec')\n",
    "#model.wv.save_word2vec_format model.wv.save_word2vec_format \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型（语义，句法）相似度度量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim import models\n",
    "\n",
    "def print_accuracy(model, questions_file):\n",
    "    print('Evaluating...\\n')\n",
    "    acc = model.accuracy(questions_file)\n",
    "    for section in acc:\n",
    "        correct = len(section['correct'])\n",
    "        total = len(section['correct']) + len(section['incorrect'])\n",
    "        total = total if total else 1\n",
    "        accuracy = 100*float(correct)/total\n",
    "        print('{:d}/{:d}, {:.2f}%, Section: {:s}'.format(correct, total, accuracy, section['section']))\n",
    "    sem_correct = sum((len(acc[i]['correct']) for i in range(5)))\n",
    "    sem_total = sum((len(acc[i]['correct']) + len(acc[i]['incorrect'])) for i in range(5))\n",
    "    print('\\nSemantic: {:d}/{:d}, Accuracy: {:.2f}%'.format(sem_correct, sem_total, 100*float(sem_correct)/sem_total))\n",
    "    \n",
    "    syn_correct = sum((len(acc[i]['correct']) for i in range(5, len(acc)-1)))\n",
    "    syn_total = sum((len(acc[i]['correct']) + len(acc[i]['incorrect'])) for i in range(5,len(acc)-1))\n",
    "    print('Syntactic: {:d}/{:d}, Accuracy: {:.2f}%\\n'.format(syn_correct, syn_total, 100*float(syn_correct)/syn_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  fastText模型在brown上的精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-20 16:26:00,159 : INFO : loading projection weights from models/brown_ft_by_anxingle.vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'tutorial.ipynb', 'brown_corp.txt', 'text8.zip', 'questions-words.txt', 'text8', 'models']\n",
      "\n",
      "Loading FastText embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-20 16:26:02,136 : INFO : loaded (15173, 100) matrix from models/brown_ft_by_anxingle.vec\n",
      "2017-06-20 16:26:02,155 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-06-20 16:26:02,359 : INFO : capital-common-countries: 1.1% (1/90)\n",
      "2017-06-20 16:26:02,534 : INFO : capital-world: 0.0% (0/44)\n",
      "2017-06-20 16:26:02,571 : INFO : currency: 0.0% (0/12)\n",
      "2017-06-20 16:26:03,640 : INFO : city-in-state: 2.6% (12/457)\n",
      "2017-06-20 16:26:04,023 : INFO : family: 17.6% (37/210)\n",
      "2017-06-20 16:26:05,459 : INFO : gram1-adjective-to-adverb: 66.5% (503/756)\n",
      "2017-06-20 16:26:05,711 : INFO : gram2-opposite: 78.0% (103/132)\n",
      "2017-06-20 16:26:07,845 : INFO : gram3-comparative: 59.3% (626/1056)\n",
      "2017-06-20 16:26:08,233 : INFO : gram4-superlative: 77.1% (162/210)\n",
      "2017-06-20 16:26:09,494 : INFO : gram5-present-participle: 64.8% (421/650)\n",
      "2017-06-20 16:26:10,060 : INFO : gram6-nationality-adjective: 32.7% (97/297)\n",
      "2017-06-20 16:26:12,568 : INFO : gram7-past-tense: 11.7% (147/1260)\n",
      "2017-06-20 16:26:13,761 : INFO : gram8-plural: 56.7% (313/552)\n",
      "2017-06-20 16:26:14,372 : INFO : gram9-plural-verbs: 71.6% (245/342)\n",
      "2017-06-20 16:26:14,374 : INFO : total: 44.0% (2667/6068)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for FastText:\n",
      "Evaluating...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-20 16:26:14,676 : INFO : capital-common-countries: 1.1% (1/90)\n",
      "2017-06-20 16:26:14,813 : INFO : capital-world: 0.0% (0/44)\n",
      "2017-06-20 16:26:14,909 : INFO : currency: 0.0% (0/12)\n",
      "2017-06-20 16:26:15,884 : INFO : city-in-state: 2.6% (12/457)\n",
      "2017-06-20 16:26:16,371 : INFO : family: 17.6% (37/210)\n",
      "2017-06-20 16:26:17,915 : INFO : gram1-adjective-to-adverb: 66.5% (503/756)\n",
      "2017-06-20 16:26:18,162 : INFO : gram2-opposite: 78.0% (103/132)\n",
      "2017-06-20 16:26:20,129 : INFO : gram3-comparative: 59.3% (626/1056)\n",
      "2017-06-20 16:26:20,580 : INFO : gram4-superlative: 77.1% (162/210)\n",
      "2017-06-20 16:26:21,802 : INFO : gram5-present-participle: 64.8% (421/650)\n",
      "2017-06-20 16:26:22,434 : INFO : gram6-nationality-adjective: 32.7% (97/297)\n",
      "2017-06-20 16:26:24,803 : INFO : gram7-past-tense: 11.7% (147/1260)\n",
      "2017-06-20 16:26:25,851 : INFO : gram8-plural: 56.7% (313/552)\n",
      "2017-06-20 16:26:26,537 : INFO : gram9-plural-verbs: 71.6% (245/342)\n",
      "2017-06-20 16:26:26,539 : INFO : total: 44.0% (2667/6068)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/90, 1.11%, Section: capital-common-countries\n",
      "0/44, 0.00%, Section: capital-world\n",
      "0/12, 0.00%, Section: currency\n",
      "12/457, 2.63%, Section: city-in-state\n",
      "37/210, 17.62%, Section: family\n",
      "503/756, 66.53%, Section: gram1-adjective-to-adverb\n",
      "103/132, 78.03%, Section: gram2-opposite\n",
      "626/1056, 59.28%, Section: gram3-comparative\n",
      "162/210, 77.14%, Section: gram4-superlative\n",
      "421/650, 64.77%, Section: gram5-present-participle\n",
      "97/297, 32.66%, Section: gram6-nationality-adjective\n",
      "147/1260, 11.67%, Section: gram7-past-tense\n",
      "313/552, 56.70%, Section: gram8-plural\n",
      "245/342, 71.64%, Section: gram9-plural-verbs\n",
      "2667/6068, 43.95%, Section: total\n",
      "\n",
      "Semantic: 50/813, Accuracy: 6.15%\n",
      "Syntactic: 2617/5255, Accuracy: 49.80%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import *\n",
    "from gensim.models import Word2Vec\n",
    "MODELS_DIR = \"models/\"\n",
    "word_analogies_file = './questions-words.txt'\n",
    "print('\\nLoading FastText embeddings')\n",
    "ft_model = KeyedVectors.load_word2vec_format(MODELS_DIR + 'brown_ft_by_anxingle.vec')\n",
    "pp = ft_model.accuracy(word_analogies_file)\n",
    "print('Accuracy for FastText:')\n",
    "print_accuracy(ft_model, word_analogies_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  word2vec模型在brown上的精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-20 16:27:44,567 : INFO : loading projection weights from models/brown_gs.vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Gensim embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-20 16:27:46,548 : INFO : loaded (15173, 100) matrix from models/brown_gs.vec\n",
      "2017-06-20 16:27:46,590 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for word2vec:\n",
      "Evaluating...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-20 16:27:46,835 : INFO : capital-common-countries: 0.0% (0/90)\n",
      "2017-06-20 16:27:46,970 : INFO : capital-world: 0.0% (0/44)\n",
      "2017-06-20 16:27:47,003 : INFO : currency: 0.0% (0/12)\n",
      "2017-06-20 16:27:47,855 : INFO : city-in-state: 0.0% (0/457)\n",
      "2017-06-20 16:27:48,270 : INFO : family: 28.1% (59/210)\n",
      "2017-06-20 16:27:49,739 : INFO : gram1-adjective-to-adverb: 0.7% (5/756)\n",
      "2017-06-20 16:27:49,976 : INFO : gram2-opposite: 0.0% (0/132)\n",
      "2017-06-20 16:27:52,109 : INFO : gram3-comparative: 6.8% (72/1056)\n",
      "2017-06-20 16:27:52,506 : INFO : gram4-superlative: 0.0% (0/210)\n",
      "2017-06-20 16:27:53,754 : INFO : gram5-present-participle: 2.2% (14/650)\n",
      "2017-06-20 16:27:54,303 : INFO : gram6-nationality-adjective: 0.0% (0/297)\n",
      "2017-06-20 16:27:56,950 : INFO : gram7-past-tense: 2.3% (29/1260)\n",
      "2017-06-20 16:27:57,943 : INFO : gram8-plural: 0.7% (4/552)\n",
      "2017-06-20 16:27:58,566 : INFO : gram9-plural-verbs: 2.3% (8/342)\n",
      "2017-06-20 16:27:58,568 : INFO : total: 3.1% (191/6068)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/90, 0.00%, Section: capital-common-countries\n",
      "0/44, 0.00%, Section: capital-world\n",
      "0/12, 0.00%, Section: currency\n",
      "0/457, 0.00%, Section: city-in-state\n",
      "59/210, 28.10%, Section: family\n",
      "5/756, 0.66%, Section: gram1-adjective-to-adverb\n",
      "0/132, 0.00%, Section: gram2-opposite\n",
      "72/1056, 6.82%, Section: gram3-comparative\n",
      "0/210, 0.00%, Section: gram4-superlative\n",
      "14/650, 2.15%, Section: gram5-present-participle\n",
      "0/297, 0.00%, Section: gram6-nationality-adjective\n",
      "29/1260, 2.30%, Section: gram7-past-tense\n",
      "4/552, 0.72%, Section: gram8-plural\n",
      "8/342, 2.34%, Section: gram9-plural-verbs\n",
      "191/6068, 3.15%, Section: total\n",
      "\n",
      "Semantic: 59/813, Accuracy: 7.26%\n",
      "Syntactic: 132/5255, Accuracy: 2.51%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nLoading Gensim embeddings')\n",
    "gs_model = KeyedVectors.load_word2vec_format(MODELS_DIR + 'brown_gs.vec')\n",
    "print('Accuracy for word2vec:')\n",
    "print_accuracy(gs_model, word_analogies_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text8语料库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fastText模型在text8语料库上的精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-20 16:49:57,652 : INFO : loading projection weights from models/text8_ft_by_anxingle.vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading FastText embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-20 16:50:06,249 : INFO : loaded (71290, 100) matrix from models/text8_ft_by_anxingle.vec\n",
      "2017-06-20 16:50:06,285 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-06-20 16:50:08,327 : INFO : capital-common-countries: 61.7% (312/506)\n",
      "2017-06-20 16:50:13,934 : INFO : capital-world: 41.4% (601/1452)\n",
      "2017-06-20 16:50:14,968 : INFO : currency: 16.0% (43/268)\n",
      "2017-06-20 16:50:20,841 : INFO : city-in-state: 16.5% (250/1511)\n",
      "2017-06-20 16:50:22,068 : INFO : family: 47.4% (145/306)\n",
      "2017-06-20 16:50:24,917 : INFO : gram1-adjective-to-adverb: 71.6% (541/756)\n",
      "2017-06-20 16:50:26,186 : INFO : gram2-opposite: 60.8% (186/306)\n",
      "2017-06-20 16:50:31,047 : INFO : gram3-comparative: 67.6% (852/1260)\n",
      "2017-06-20 16:50:33,030 : INFO : gram4-superlative: 55.7% (282/506)\n",
      "2017-06-20 16:50:36,696 : INFO : gram5-present-participle: 54.6% (542/992)\n",
      "2017-06-20 16:50:41,580 : INFO : gram6-nationality-adjective: 94.4% (1294/1371)\n",
      "2017-06-20 16:50:46,075 : INFO : gram7-past-tense: 33.8% (450/1332)\n",
      "2017-06-20 16:50:49,588 : INFO : gram8-plural: 87.9% (872/992)\n",
      "2017-06-20 16:50:51,976 : INFO : gram9-plural-verbs: 58.9% (383/650)\n",
      "2017-06-20 16:50:51,978 : INFO : total: 55.3% (6753/12208)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for FastText:\n",
      "Evaluating...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-20 16:50:53,909 : INFO : capital-common-countries: 61.7% (312/506)\n",
      "2017-06-20 16:50:59,284 : INFO : capital-world: 41.4% (601/1452)\n",
      "2017-06-20 16:51:00,254 : INFO : currency: 16.0% (43/268)\n",
      "2017-06-20 16:51:05,645 : INFO : city-in-state: 16.5% (250/1511)\n",
      "2017-06-20 16:51:06,731 : INFO : family: 47.4% (145/306)\n",
      "2017-06-20 16:51:09,689 : INFO : gram1-adjective-to-adverb: 71.6% (541/756)\n",
      "2017-06-20 16:51:10,864 : INFO : gram2-opposite: 60.8% (186/306)\n",
      "2017-06-20 16:51:15,764 : INFO : gram3-comparative: 67.6% (852/1260)\n",
      "2017-06-20 16:51:17,840 : INFO : gram4-superlative: 55.7% (282/506)\n",
      "2017-06-20 16:51:21,565 : INFO : gram5-present-participle: 54.6% (542/992)\n",
      "2017-06-20 16:51:26,879 : INFO : gram6-nationality-adjective: 94.4% (1294/1371)\n",
      "2017-06-20 16:51:32,035 : INFO : gram7-past-tense: 33.8% (450/1332)\n",
      "2017-06-20 16:51:35,822 : INFO : gram8-plural: 87.9% (872/992)\n",
      "2017-06-20 16:51:38,400 : INFO : gram9-plural-verbs: 58.9% (383/650)\n",
      "2017-06-20 16:51:38,402 : INFO : total: 55.3% (6753/12208)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/506, 61.66%, Section: capital-common-countries\n",
      "601/1452, 41.39%, Section: capital-world\n",
      "43/268, 16.04%, Section: currency\n",
      "250/1511, 16.55%, Section: city-in-state\n",
      "145/306, 47.39%, Section: family\n",
      "541/756, 71.56%, Section: gram1-adjective-to-adverb\n",
      "186/306, 60.78%, Section: gram2-opposite\n",
      "852/1260, 67.62%, Section: gram3-comparative\n",
      "282/506, 55.73%, Section: gram4-superlative\n",
      "542/992, 54.64%, Section: gram5-present-participle\n",
      "1294/1371, 94.38%, Section: gram6-nationality-adjective\n",
      "450/1332, 33.78%, Section: gram7-past-tense\n",
      "872/992, 87.90%, Section: gram8-plural\n",
      "383/650, 58.92%, Section: gram9-plural-verbs\n",
      "6753/12208, 55.32%, Section: total\n",
      "\n",
      "Semantic: 1351/4043, Accuracy: 33.42%\n",
      "Syntactic: 5402/8165, Accuracy: 66.16%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nLoading FastText embeddings')\n",
    "word_analogies_file = './questions-words.txt'\n",
    "ft_model = KeyedVectors.load_word2vec_format(MODELS_DIR + 'text8_ft_by_anxingle.vec')\n",
    "pp = ft_model.accuracy(word_analogies_file)\n",
    "print('Accuracy for FastText:')\n",
    "print_accuracy(ft_model, word_analogies_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word2vec在text8上的精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-20 16:51:48,220 : INFO : loading projection weights from models/text8_gs.vec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading word2vec embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-20 16:51:57,509 : INFO : loaded (71290, 100) matrix from models/text8_gs.vec\n",
      "2017-06-20 16:51:57,574 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-06-20 16:51:59,438 : INFO : capital-common-countries: 26.7% (135/506)\n",
      "2017-06-20 16:52:05,241 : INFO : capital-world: 16.9% (245/1452)\n",
      "2017-06-20 16:52:06,283 : INFO : currency: 9.3% (25/268)\n",
      "2017-06-20 16:52:12,544 : INFO : city-in-state: 8.8% (139/1571)\n",
      "2017-06-20 16:52:13,643 : INFO : family: 75.8% (232/306)\n",
      "2017-06-20 16:52:16,669 : INFO : gram1-adjective-to-adverb: 11.6% (88/756)\n",
      "2017-06-20 16:52:17,884 : INFO : gram2-opposite: 14.7% (45/306)\n",
      "2017-06-20 16:52:22,815 : INFO : gram3-comparative: 56.3% (709/1260)\n",
      "2017-06-20 16:52:24,777 : INFO : gram4-superlative: 37.5% (190/506)\n",
      "2017-06-20 16:52:28,598 : INFO : gram5-present-participle: 30.7% (305/992)\n",
      "2017-06-20 16:52:33,983 : INFO : gram6-nationality-adjective: 49.5% (679/1371)\n",
      "2017-06-20 16:52:39,184 : INFO : gram7-past-tense: 25.8% (344/1332)\n",
      "2017-06-20 16:52:43,071 : INFO : gram8-plural: 38.1% (378/992)\n",
      "2017-06-20 16:52:45,637 : INFO : gram9-plural-verbs: 31.4% (204/650)\n",
      "2017-06-20 16:52:45,639 : INFO : total: 30.3% (3718/12268)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for FastText:\n",
      "Evaluating...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-20 16:52:47,683 : INFO : capital-common-countries: 26.7% (135/506)\n",
      "2017-06-20 16:52:53,311 : INFO : capital-world: 16.9% (245/1452)\n",
      "2017-06-20 16:52:54,340 : INFO : currency: 9.3% (25/268)\n",
      "2017-06-20 16:53:00,472 : INFO : city-in-state: 8.8% (139/1571)\n",
      "2017-06-20 16:53:01,643 : INFO : family: 75.8% (232/306)\n",
      "2017-06-20 16:53:04,571 : INFO : gram1-adjective-to-adverb: 11.6% (88/756)\n",
      "2017-06-20 16:53:05,763 : INFO : gram2-opposite: 14.7% (45/306)\n",
      "2017-06-20 16:53:10,758 : INFO : gram3-comparative: 56.3% (709/1260)\n",
      "2017-06-20 16:53:12,663 : INFO : gram4-superlative: 37.5% (190/506)\n",
      "2017-06-20 16:53:16,499 : INFO : gram5-present-participle: 30.7% (305/992)\n",
      "2017-06-20 16:53:21,788 : INFO : gram6-nationality-adjective: 49.5% (679/1371)\n",
      "2017-06-20 16:53:26,986 : INFO : gram7-past-tense: 25.8% (344/1332)\n",
      "2017-06-20 16:53:30,789 : INFO : gram8-plural: 38.1% (378/992)\n",
      "2017-06-20 16:53:33,274 : INFO : gram9-plural-verbs: 31.4% (204/650)\n",
      "2017-06-20 16:53:33,276 : INFO : total: 30.3% (3718/12268)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/506, 26.68%, Section: capital-common-countries\n",
      "245/1452, 16.87%, Section: capital-world\n",
      "25/268, 9.33%, Section: currency\n",
      "139/1571, 8.85%, Section: city-in-state\n",
      "232/306, 75.82%, Section: family\n",
      "88/756, 11.64%, Section: gram1-adjective-to-adverb\n",
      "45/306, 14.71%, Section: gram2-opposite\n",
      "709/1260, 56.27%, Section: gram3-comparative\n",
      "190/506, 37.55%, Section: gram4-superlative\n",
      "305/992, 30.75%, Section: gram5-present-participle\n",
      "679/1371, 49.53%, Section: gram6-nationality-adjective\n",
      "344/1332, 25.83%, Section: gram7-past-tense\n",
      "378/992, 38.10%, Section: gram8-plural\n",
      "204/650, 31.38%, Section: gram9-plural-verbs\n",
      "3718/12268, 30.31%, Section: total\n",
      "\n",
      "Semantic: 776/4103, Accuracy: 18.91%\n",
      "Syntactic: 2942/8165, Accuracy: 36.03%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nLoading word2vec embeddings')\n",
    "ft_model = KeyedVectors.load_word2vec_format(MODELS_DIR + 'text8_gs.vec')\n",
    "pp = ft_model.accuracy(word_analogies_file)\n",
    "print('Accuracy for FastText:')\n",
    "print_accuracy(ft_model, word_analogies_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
